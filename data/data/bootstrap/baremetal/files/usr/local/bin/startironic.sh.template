#!/bin/bash
set -ex

# Must match ironic.service
EXIT_CODE_NO_RESTART=42

# First we stop any previously started containers, because ExecStop only runs when the ExecStart process
# e.g this script is still running, but we exit if *any* of the containers exits unexpectedly
for name in ironic ironic-inspector ironic-ramdisk-logs httpd coreos-downloader image-customization; do
    podman ps | grep -w "$name$" && podman kill $name
    podman ps --all | grep -w "$name$" && podman rm $name -f
done

IRONIC_SHARED_VOLUME="systemd-ironic"

# Apparently network-online doesn't necessarily mean iptables is ready, so wait until it is..
while ! iptables -L; do
  sleep 1
done

# Start dnsmasq, http, and ironic containers using same image
# Currently we do this outside of a pod because we need to ensure the images
# are downloaded before starting the API pods

podman run -d --name coreos-downloader \
     --restart on-failure \
     --env "IP_OPTIONS=${PROVISIONING_IP_OPTIONS}" \
     -v $IRONIC_SHARED_VOLUME:/shared:z \
     ${MACHINE_OS_IMAGES_IMAGE} /bin/copy-metal --all /shared/html/images/

# Wait for images to be downloaded/ready
podman wait -i 1000ms coreos-downloader

podman run -d --net host --name httpd \
     --restart on-failure \
     --env IRONIC_RAMDISK_SSH_KEY="$IRONIC_RAMDISK_SSH_KEY" \
     --env PROVISIONING_INTERFACE \
     --env HTTP_PORT=$HTTP_PORT \
     -v $IRONIC_SHARED_VOLUME:/shared:z --entrypoint /bin/runhttpd ${IRONIC_IMAGE}

# Add firewall rules to ensure the IPA ramdisk can reach httpd, Ironic and the Inspector API on the host
for port in 5050 $HTTP_PORT 6385 ; do
    if ! $IPTABLES -C INPUT -i $PROVISIONING_INTERFACE -p tcp -m tcp --dport $port -j ACCEPT > /dev/null 2>&1; then
        $IPTABLES -I INPUT -i $PROVISIONING_INTERFACE -p tcp -m tcp --dport $port -j ACCEPT
    fi
done

# It is possible machine-api-operator comes up while the bootstrap is
# online, meaning there could be two DHCP servers on the network. To
# avoid bootstrap responding to a worker, which would cause a failed
# deployment, we filter out requests from anyone else than the control
# plane.  We are using iptables instead of dnsmasq's dhcp-host because
# DHCPv6 wants to use DUID's instead of mac addresses.
{{if .PlatformData.BareMetal.ProvisioningDHCPAllowList}}

# Remove old references to the DHCP_IRONIC chain
$IPTABLES-save -t raw | grep -v DHCP_IRONIC | $IPTABLES-restore

$IPTABLES -t raw -N DHCP_IRONIC
$IPTABLES -t raw -A PREROUTING -p udp --dport 67 -j DHCP_IRONIC
$IPTABLES -t raw -A PREROUTING -p udp --dport 547 -j DHCP_IRONIC

for mac in {{.PlatformData.BareMetal.ProvisioningDHCPAllowList}}
do
  $IPTABLES -t raw -A DHCP_IRONIC -m mac --mac-source "$mac" -j ACCEPT
done

$IPTABLES -t raw -A DHCP_IRONIC -j DROP
{{end}}

export KUBECONFIG=/opt/openshift/auth/kubeconfig-loopback

mkdir -p /tmp/nmstate

{{range .PlatformData.BareMetal.Hosts}}
    until oc get -n openshift-machine-api baremetalhost {{.Name}}; do
        echo Waiting for Host {{.Name}} to appear...
        sleep 10
    done
    secret_name=$(oc get -n openshift-machine-api baremetalhost {{.Name}} -o jsonpath="{.spec.preprovisioningNetworkDataName}")
    if [ -n "${secret_name}" ]; then
        until oc get -n openshift-machine-api secret "${secret_name}"; do
            echo Waiting for Secret "${secret_name}" to appear...
            sleep 10
        done
        oc get -n openshift-machine-api secret ${secret_name} -o jsonpath="{.data.nmstate}" | base64 -d > /tmp/nmstate/{{.Name}}.yaml
    else
        touch /tmp/nmstate/{{.Name}}.yaml
    fi
{{end}}

# Create a podman secret for the image-customization-server 
podman secret rm pull-secret || true
base64 -w 0 /root/.docker/config.json | podman secret create pull-secret -

# Embed agent ignition into the rhcos live iso
podman run -d --net host --name image-customization \
    --env DEPLOY_ISO="/shared/html/images/ironic-python-agent.iso" \
    --env DEPLOY_INITRD="/shared/html/images/ironic-python-agent.initramfs" \
    --env IRONIC_BASE_URL \
    --env IRONIC_RAMDISK_SSH_KEY \
    --env IRONIC_AGENT_IMAGE \
    --env IP_OPTIONS=$EXTERNAL_IP_OPTIONS \
    --env REGISTRIES_CONF_PATH=/tmp/containers/registries.conf \
    --entrypoint '["/image-customization-server", "--nmstate-dir=/tmp/nmstate/", "--images-publish-addr=http://0.0.0.0:8084"]' \
    -v /tmp/nmstate/:/tmp/nmstate/:z,ro \
    -v $IRONIC_SHARED_VOLUME:/shared:z \
    -v /etc/containers:/tmp/containers:z \
    --secret pull-secret,mode=400 \
    ${CUSTOMIZATION_IMAGE}

podman run -d --net host --name ironic \
     --restart on-failure \
     --env IRONIC_RAMDISK_SSH_KEY \
     --env PROVISIONING_INTERFACE \
     --env OS_CONDUCTOR__HEARTBEAT_TIMEOUT=120 \
     --env IRONIC_HTPASSWD \
     --env INSPECTOR_HTPASSWD=${IRONIC_HTPASSWD} \
     --env IRONIC_KERNEL_PARAMS \
     --env HTTP_PORT \
     --entrypoint /bin/runironic \
     -v $AUTH_DIR:/auth:z,ro \
     -v $IRONIC_SHARED_VOLUME:/shared:z ${IRONIC_IMAGE}

podman run -d --net host --name ironic-inspector \
     --restart on-failure \
     --env PROVISIONING_INTERFACE \
     --env IRONIC_HTPASSWD \
     --env INSPECTOR_HTPASSWD=${IRONIC_HTPASSWD} \
     --env IRONIC_KERNEL_PARAMS \
     --env HTTP_PORT \
     --entrypoint /bin/runironic-inspector \
     -v $AUTH_DIR:/auth:z,ro \
     -v $IRONIC_SHARED_VOLUME:/shared:z "${IRONIC_IMAGE}"

podman run -d --name ironic-ramdisk-logs \
     --restart on-failure \
     --entrypoint /bin/runlogwatch.sh \
     -v $IRONIC_SHARED_VOLUME:/shared:z ${IRONIC_IMAGE}

# Failure to start image-customization results in a very confusing error
sleep 10
icc_id=$(podman ps --filter name=image-customization --filter status=running --format '{{`{{.ID}}`}}')
if [ -z "$icc_id" ]; then
    echo The image-customization service crashed after start, check its logs
    exit $EXIT_CODE_NO_RESTART
fi
